# Project Research Summary

**Project:** Wellness & Sensory Connection Assistant
**Domain:** Voice-guided intimate wellness AI for adults
**Researched:** 2026-02-21
**Confidence:** MEDIUM-HIGH

## Executive Summary

This is a voice-first, AI-generated guided wellness product that occupies an underserved niche at the intersection of meditation apps (Calm, Headspace) and AI companion experiences (Replika, Blush). The product delivers real-time, infinitely varied guided sessions across a structured 5-phase arc (Atmosphere, Breathing, Sensory, Relaxation, Resolution), with the AI guide's voice as the primary product interface. Experts build this type of product as a cascading streaming pipeline: text is generated by an LLM, chunked at sentence boundaries, filtered for safety, and converted to audio via TTS — all in an overlapping pipeline so the user hears the first audio within 1-2 seconds of session start. This architecture is 5-10x cheaper than OpenAI's Realtime API, provides full text visibility for content safety, and keeps LLM and TTS providers independently swappable.

The recommended technical approach is Next.js 16 with the OpenAI Responses API (GPT-4o-mini) for text generation, ElevenLabs for TTS (best-in-class voice naturalness for long-form wellness content), Neon/PostgreSQL for persistent storage, and Upstash Redis for ephemeral session state. The entire stack is Vercel-deployable and TypeScript-first. The critical early decision is TTS voice selection: the product's core value proposition is the quality and warmth of the AI guide's voice, and this cannot be easily changed post-launch without breaking user trust. ElevenLabs must be evaluated with real wellness script content (3-5 minute monologues) before build begins.

The most dangerous risks are non-technical: payment processor rejection (Stripe/PayPal explicitly prohibit intimate wellness content), regulatory non-compliance with enacted AI companion laws (California SB 243, New York AI Companion Models Law, both effective 2025-2026), and jailbreak-driven content boundary violations. These must be treated as launch blockers, not afterthoughts. The product is legal and viable, but only if the legal-compliance and safety-filtering foundations are established before any user-facing features are shipped.

## Key Findings

### Recommended Stack

The stack is well-suited to the product's streaming-heavy, serverless-friendly requirements. Next.js 16 handles both the React frontend and server-side API routes in one deployment target, with native streaming response support. The OpenAI Responses API (replacing Chat Completions as of March 2025) brings built-in conversation state management via `previous_response_id` chaining, reducing manual context assembly complexity. ElevenLabs is the primary TTS provider with OpenAI's gpt-4o-mini-tts as a cost-saving fallback tier; the voice quality difference is meaningful for long-form wellness content and justifies the price premium. Neon PostgreSQL handles durable storage (users, consent records, session history) while Upstash Redis handles ephemeral session state with TTL-based auto-expiry. Estimated monthly cost at 1,000 users is $200-400/mo, with ElevenLabs TTS as the dominant line item.

**Core technologies:**
- **Next.js 16.1.6**: Full-stack framework — handles frontend and streaming API routes in one Vercel deployment
- **OpenAI Responses API (gpt-4o-mini)**: LLM text generation — stateful chaining reduces context assembly; better cache hit rates
- **ElevenLabs SDK 2.36.0**: Primary TTS — 81.97% pronunciation accuracy, 44.98% high naturalness rating; best for long-form wellness voice
- **OpenAI gpt-4o-mini-tts**: Fallback TTS — ~5x cheaper than ElevenLabs; adequate for non-premium tiers
- **Vercel AI SDK**: Streaming helpers — `streamText()`, `useChat()` abstractions over SSE/streaming plumbing
- **Neon (Serverless PostgreSQL)**: Persistent storage — native Vercel integration, serverless driver, auto-scaling to zero
- **Drizzle ORM 0.45.1**: Database access — TypeScript-first, lightweight vs. Prisma, no cold-start binary overhead
- **Upstash Redis**: Session state — HTTP-based Redis; pay-per-request; TTL-based session expiry; no connection management
- **Auth.js v5 (NextAuth)**: Authentication — App Router-native, OAuth + magic links, self-hosted (no per-user cost)
- **Zod 4.3.6**: Schema validation — validate all API inputs, session state, LLM response shapes, environment variables
- **Tailwind CSS 4.2.0**: Styling — CSS-first `@theme` config maps perfectly to the fixed pink wellness palette

### Expected Features

The product's feature landscape is well-understood through competitor analysis (Calm, Headspace, Replika, Blush, RelaxFrens, Insight Timer). The core differentiator — real-time AI-generated sessions rather than pre-recorded content — is technically achievable and not yet well-executed by any competitor in the intimate wellness niche. The 5-phase session structure is both the product's UX design and its architectural backbone.

**Must have (table stakes):**
- **Streaming TTS voice output** — the product IS the voice; choppy or robotic audio is an instant product failure
- **5-phase structured session flow** (Atmosphere > Breathing > Sensory > Relaxation > Resolution) — expected session arc
- **Session length options** (10/15/20/30 min) — users expect schedule control; competitors all offer this
- **Basic playback controls** (pause, resume, end) — non-negotiable for any audio experience
- **Age gate** — legal launch blocker; simple DOB entry at minimum; GUARD Act requires more robust verification
- **Consent gates before intimate content** — ethical and legal requirement; must precede Phase 3 (Sensory)
- **Content safety guardrails** — system prompt + output classifier; must ship from day one, not bolted on later
- **Privacy-first data architecture** — no session transcript storage; GDPR compliance; right to deletion
- **Responsive web UI** — pink wellness theme; mobile-optimized; minimal chrome during sessions

**Should have (competitive differentiators):**
- **Real-time AI-generated sessions** — infinite variety; no competitor executes this well for intimacy/body awareness
- **Mood-based session selection** — pre-session emotional state input adapts session emphasis; low complexity, high value
- **Background ambient soundscapes** — sessions feel bare without layered audio; add after core TTS works
- **Graceful boundary negotiation** — AI redirects gently rather than issuing jarring hard blocks
- **Conversational interactivity (text)** — mid-session check-ins for user agency; more intimate than pure monologue
- **Multiple curated voice options** — 2-3 ElevenLabs voices with distinct warmth profiles
- **User preference profiles** — remember preferred length, voice, pacing, soundscape across sessions

**Defer (v2+):**
- Adaptive personalization over time (requires session history corpus)
- Progressive multi-session series (requires series-aware content planning)
- Voice input during sessions (STT adds latency, mobile mic permissions are unreliable)
- Wearable/biometric integration

**Anti-features (never build):**
- User voice cloning (legal consent liability)
- Social features (breaks private safe-space nature)
- Gamification / streaks (creates anxiety; antithetical to wellness)
- Explicit sexual content (legal, ethical, platform risk — firm brand boundary)
- Therapy or clinical claims (FDA/regulatory minefield)

### Architecture Approach

The system is built as a server-authoritative streaming pipeline with WebSocket-based communication between client and server. The client is a "dumb" audio player with controls — it mirrors UI state but makes no LLM or TTS decisions and does not store conversation history. All prompt assembly, phase logic, safety filtering, and session state live server-side. The Session Orchestrator is the central coordinator: it reads from Redis, checks the Phase State Machine for transition triggers, assembles prompts, and drives the generate-speak pipeline. The pipeline runs in parallel — while TTS synthesizes sentence N, the LLM is already generating sentence N+1, achieving 1-2 second time-to-first-audio.

**Major components:**
1. **WebSocket Gateway** — persistent connection manager; routes binary audio frames and JSON control messages between client and server
2. **Session Orchestrator + Phase State Machine** — the "brain"; manages the 5-phase FSM, assembles prompts, drives the pipeline; reads/writes Redis session state
3. **Safety Filter Layer** — runs on every sentence between LLM output and TTS input; keyword blocklist + OpenAI Moderation API; replaces unsafe sentences with pre-written fallbacks
4. **LLM Service** — streams from OpenAI Responses API; sentence chunker emits at natural boundaries (`.!?` + whitespace, min 40 chars); yields `AsyncIterable<string>`
5. **TTS Service** — converts sentence chunks to audio via ElevenLabs WebSocket; yields `AsyncIterable<ArrayBuffer>` of audio chunks
6. **Session Store (Redis)** — session JSON with TTL (1 hr); stores phase, history, consent status, preferences; never stores transcripts
7. **Audio Playback Queue (Client)** — double-buffer Web Audio API queue; tolerates network jitter; plays audio chunks seamlessly in sequence

**Key architectural decisions:**
- Cascading pipeline (NOT OpenAI Realtime API) — 5-10x cheaper, full text visibility for safety, provider-agnostic
- Server-authoritative safety — client cannot modify prompt assembly or bypass content filters
- Sentence-boundary chunking — TTS requires complete sentences (min ~40 chars) for natural prosody; too-small chunks produce choppy audio

### Critical Pitfalls

1. **Payment processor rejection** — Stripe and PayPal explicitly prohibit intimate wellness content. Use a high-risk processor (CCBill, Segpay, Verotel, Epoch) from day one. Never integrate Stripe; migration after account freeze is painful and slow.

2. **Regulatory non-compliance with AI companion laws** — California SB 243 (effective Jan 2026), New York AI Companion Models Law (effective Nov 2025), and the federal GUARD Act mandate: "This is an AI" disclosure at session start, age verification beyond checkbox, and crisis-response escalation for self-harm expressions. Fines up to $100K per violation. These are launch blockers.

3. **Jailbreak-driven content boundary violation** — the intimate-to-explicit content boundary is linguistically fuzzy and users will probe it. System prompt alone is insufficient. Implement layered safety: prompt + output classifier (per-sentence before TTS) + keyword blocklist + behavioral monitoring. Build a red-team test suite of 100+ jailbreak attempts targeting this boundary and run it in CI/CD.

4. **TTS voice uncanny valley** — wellness sessions are sustained monologue with emotional modulation; the hardest TTS challenge. Evaluate providers with 3-5 minute wellness scripts (not 10-second demos) before committing. Lock voice parameters (voice ID, speed, stability, pitch) in config and test with real users in the target demographic.

5. **Streaming audio latency destroying session flow** — the cascading pipeline must achieve under 1-2 seconds to first audio. Monitor p95 TTFA, alert on audio gaps > 1 second. Implement graceful degradation (extend current content/pause naturally) rather than hard cuts when latency spikes. Pre-generate common transitional phrases to fill pipeline gaps.

## Implications for Roadmap

Based on cross-research synthesis, 5 phases are recommended, ordered by dependency chain and risk mitigation priority.

### Phase 1: Legal, Safety, and Infrastructure Foundation

**Rationale:** Multiple pitfalls (payment processor, regulatory compliance, system prompt extraction, content boundaries) are launch blockers that must be established before any user-facing feature is built. Retrofitting safety and legal compliance is more expensive than building them first. The Session Store, WebSocket Gateway skeleton, and type interfaces are also required before anything else can be built or tested.

**Delivers:** Payment processor integrated (high-risk processor), age verification implemented, AI disclosure and consent framework built, layered safety architecture (Safety Service with OpenAI Moderation API integration), Redis session store with schema, WebSocket gateway skeleton, TypeScript types for all session/message/safety types, Neon database schema with Drizzle, Auth.js authentication, crisis detection and escalation routing.

**Addresses:** Age gate, consent gates, content safety guardrails, privacy-first data architecture (no transcript storage, TTL-based session expiry).

**Avoids:** Pitfall 1 (payment processor rejection), Pitfall 2 (system prompt extraction), Pitfall 3 (regulatory non-compliance), Pitfall 4 (jailbreak content violation), Pitfall 8 (intimate data mishandling), Pitfall 9 (wellness-therapy liability), Pitfall 10 (cloud AUP violation — document content policy early).

**Research flag:** Needs `/gsd:research-phase` — regulatory requirements are complex, jurisdiction-specific, and evolving rapidly. The exact scope of age verification required (simple DOB vs. ID verification service) needs legal counsel input. Payment processor selection and integration requirements need direct vendor research.

### Phase 2: Core Streaming Pipeline

**Rationale:** The cascading LLM-to-TTS pipeline is the product's technical core and highest-risk implementation challenge. It must be built and validated before session orchestration logic can be layered on top. TTS voice selection is an irreversible early decision — changing voices later breaks user trust. This phase also requires the foundation from Phase 1 (types, session store, WebSocket gateway) to exist.

**Delivers:** Functional cascading pipeline (LLM streaming -> sentence chunker -> safety filter -> TTS streaming -> WebSocket -> client audio queue), ElevenLabs WebSocket integration with connection pooling, OpenAI Responses API integration with streaming, sentence-boundary chunking (min 40-char threshold), double-buffer audio playback queue on client, end-to-end latency validation (p95 TTFA < 1.5s target), TTS voice selected and parameters locked in config.

**Uses:** `@elevenlabs/elevenlabs-js 2.36.0`, `openai 6.22.0`, Vercel AI SDK `streamText()`, Web Audio API, `@upstash/redis`.

**Implements:** LLM Service, TTS Service, sentence chunker (lib/audio/sentenceChunker.ts), Audio Playback Queue (client), WebSocket message routing.

**Avoids:** Pitfall 5 (uncanny valley — voice evaluated on real wellness content before build), Pitfall 6 (streaming latency — architecture designed for pipelined parallelism).

**Research flag:** Consider `/gsd:research-phase` for ElevenLabs WebSocket streaming integration specifics — the multi-context WebSocket, chunk_length_schedule, and optimal audio format (PCM vs MP3) for low-latency wellness use cases have tradeoffs that benefit from dedicated research.

### Phase 3: Session Intelligence and Orchestration

**Rationale:** Phase State Machine and Session Orchestrator require the pipeline from Phase 2 to exist before they can be meaningfully tested — you need the generate-speak pipeline working before orchestration logic can drive it. The 5-phase flow is the product's experience design; getting it right requires end-to-end session testing that the previous phases enable.

**Delivers:** Phase State Machine (FSM for 5-phase flow with configurable min/max durations and transition triggers), Session Orchestrator integrating pipeline + state machine + Redis, phase-specific system prompt segments (lib/prompts/phases.ts), consent gate enforcement per phase (consent required before Phase 3: Sensory), session lifecycle management (create, phase transitions, end, auto-resolution), 5 phase definitions with distinct tone/pacing guidance.

**Uses:** Upstash Redis (session state), OpenAI Responses API (`previous_response_id` chaining for conversation continuity), Zod (session state validation).

**Implements:** PhaseStateMachine.ts, SessionOrchestrator.ts, phase prompt files (atmosphere.ts, breathing.ts, sensory.ts, relaxation.ts, resolution.ts), session lifecycle REST + WebSocket handlers.

**Avoids:** Pitfall 7 (context drift — phase-aware prompting, structured session summaries, limited history window), Pitfall 13 (session recovery — Redis-backed state persists across WebSocket disconnections).

**Research flag:** Standard patterns — phase state machines and LLM prompt engineering for structured sessions are well-documented. Skip `/gsd:research-phase`.

### Phase 4: Client Experience and UI

**Rationale:** The client is a consumer of everything built in Phases 1-3. Building it last means the UI can be built against a real working pipeline (not mocks), leading to better UX decisions. The pink wellness theme and responsive design are straightforward to implement once the underlying session API is stable. This phase can be developed partially in parallel with Phase 3 if teams allow.

**Delivers:** Full session UI (SessionPlayer, PhaseIndicator, SessionControls, ConsentGate components), pink wellness theme (Tailwind v4 @theme with --color-blush: #F8C8DC, --color-rose: #D63384, --color-charcoal: #2B2B2B), responsive mobile-optimized layout, consent flow woven into session start (conversational, not clinical), WebSocket client hooks (useWebSocket.ts, useAudioQueue.ts, useSession.ts), session length selection UI (10/15/20/30 min), phase progress indicator, waveform/ambient visual during active sessions, Framer Motion transitions between phases.

**Addresses:** Responsive web UI, basic playback controls, consent UX (conversational rather than clinical modals).

**Avoids:** Pitfall 15 (consent gates feeling clinical — consent woven into AI guide's opening dialogue), Pitfall 12 (voice inconsistency — locked TTS parameters from Phase 2 config).

**Research flag:** Standard patterns — Next.js App Router, React hooks, Tailwind v4 are well-documented. Skip `/gsd:research-phase`.

### Phase 5: Differentiators and Launch Readiness

**Rationale:** Post-core validation phase that adds the features elevating the product above basic functionality. These features require real user feedback to prioritize correctly — shipping them before validating core sessions risks building the wrong things. This phase also handles launch readiness (monitoring, rate limiting, cost controls).

**Delivers:** Mood-based session selection (pre-session emotional state -> session emphasis adaptation), background ambient soundscapes with voice/ambient volume mixer (3-5 soundscape options), multiple curated voice options (2-3 ElevenLabs voices with personality profiles), session aftercare enhancements (post-session reflection, grounding), rate limiting on TTS endpoints (`@upstash/ratelimit`), session length limits for cost control, TTFA monitoring and alerting, red-team jailbreak test suite in CI/CD, privacy audit (verify no transcript leakage to Sentry/Datadog), launch checklist (regulatory disclosures, crisis routing, AUP documentation).

**Addresses:** Background soundscapes, mood-based selection, multiple voice options, graceful boundary negotiation (refined), session aftercare.

**Avoids:** Pitfall 14 (TTS cost explosion — rate limiting, session length caps, cost modeling per session before launch), Pitfall 11 (age verification scope — evaluate regulatory requirements with counsel before deciding on enhanced ID verification).

**Research flag:** Consider `/gsd:research-phase` for soundscape audio mixing in the browser (Web Audio API multi-track mixing with the TTS stream has specific implementation patterns) and for cost optimization strategies (pre-generating common phrases, batch TTS efficiency).

### Phase Ordering Rationale

- **Safety and legal first** because retrofitting compliance is a rewrite; payment processor must be correct before any monetization path exists; and regulatory disclosure requirements affect every user-facing interaction from session start.
- **Pipeline before orchestration** because the Phase State Machine can only be meaningfully tested against a real streaming pipeline; hardcoded prompts can validate LLM-to-TTS end-to-end before phase logic is added.
- **Orchestration before UI** because the UI is a consumer of the session API; building UI against a stable API (not mocks) produces better UX decisions and avoids rework.
- **Differentiators last** because mood selection, soundscapes, and multiple voices are meaningfully prioritizable only after real user sessions reveal what users actually need — the product hypothesis should be validated first.

### Research Flags

Phases needing deeper research during planning:
- **Phase 1:** Regulatory scope of age verification (DOB vs. ID verification service), crisis detection implementation, and high-risk payment processor integration requirements are jurisdiction-specific and evolving. Requires legal counsel input and direct vendor research.
- **Phase 2:** ElevenLabs WebSocket streaming specifics — chunk_length_schedule, multi-context connection management, PCM vs. MP3 audio format tradeoffs for low-latency delivery. Recommend dedicated research before API integration build begins.
- **Phase 5:** Web Audio API multi-track mixing (TTS stream + ambient soundscape layer) has specific browser compatibility patterns. TTS cost optimization strategies (pre-generation, batching) need unit economics modeling before implementation.

Phases with standard patterns (can skip `/gsd:research-phase`):
- **Phase 3:** Phase state machines and LLM prompt engineering for structured sessions are well-documented patterns.
- **Phase 4:** Next.js App Router, React hooks, Tailwind v4 CSS-first theming are standard and well-documented.

## Confidence Assessment

| Area | Confidence | Notes |
|------|------------|-------|
| Stack | HIGH | All versions verified via npm registry 2026-02-21; official docs consulted for all primary dependencies; TTS provider comparison based on multiple benchmark sources |
| Features | MEDIUM | Competitor analysis is thorough (Calm, Headspace, Replika, Blush, RelaxFrens); the intimate wellness AI niche is newer with fewer public references; MVP definition is well-reasoned but requires user validation |
| Architecture | MEDIUM-HIGH | Cascading pipeline pattern is well-documented; WebSocket audio streaming is established; session orchestration pattern is sound; specific ElevenLabs WebSocket streaming integration details are lower-confidence (fewer community references for wellness-specific use) |
| Pitfalls | HIGH | Legal pitfalls are based on enacted legislation (HIGH confidence sources); safety/jailbreak patterns are from OWASP and security research; payment processor restrictions are explicitly documented; TTS uncanny valley and latency pitfalls are from official provider documentation and benchmarks |

**Overall confidence:** MEDIUM-HIGH

### Gaps to Address

- **Age verification scope:** The GUARD Act is proposed but not enacted at federal level; California and New York state laws are enacted. The exact technical implementation required (DOB date entry vs. third-party ID verification service like Jumio/Persona) depends on jurisdiction interpretation. Consult a healthcare/tech attorney before Phase 1 spec is finalized.
- **Cloud AUP review:** Vercel's acceptable use policy for intimate wellness content has not been explicitly confirmed. Must review Vercel's AUP and document how the product differs from prohibited categories before building on their platform.
- **ElevenLabs voice selection:** The specific voice ID to use as the primary guide voice has not been determined. This is a product decision requiring listening tests with wellness script content. It must be finalized before Phase 2 begins.
- **Auth.js v5 beta stability:** Auth.js v5 is `beta.30` — the ecosystem has standardized on it, but it is not a stable release. Monitor for breaking changes and have a contingency plan (Clerk as fallback) if beta behavior causes issues.
- **Session content depth:** The 5-phase structure and system prompt design are defined architecturally but not in content detail. The quality of wellness session content depends heavily on system prompt engineering — this is a product creative challenge, not just a technical one, and needs dedicated attention before Phase 3.

## Sources

### Primary (HIGH confidence)
- OpenAI Responses API docs — LLM streaming, `previous_response_id` chaining, pricing
- ElevenLabs WebSocket TTS documentation — streaming integration, voice quality benchmarks
- npm registry version checks (2026-02-21) — all dependency versions verified
- OWASP LLM01:2025 Prompt Injection — safety architecture requirements
- California SB 243 text (California Legislature) — regulatory requirements
- New York AI Companion Models Law (Morrison Foerster analysis) — regulatory requirements
- Stripe Prohibited Businesses FAQ — payment processor restrictions
- Redis session management docs — session store patterns
- Web Audio API (MDN) — client-side audio playback architecture
- Neon serverless PostgreSQL docs — database integration patterns
- Tailwind CSS v4 release notes — CSS-first configuration approach
- Next.js 16 release blog — App Router streaming support
- ElevenLabs latency optimization docs — TTFA benchmarks and best practices

### Secondary (MEDIUM confidence)
- AssemblyAI voice AI stack guide — ecosystem overview, pipeline patterns
- Softcery real-time vs. turn-based voice agent architecture — architectural tradeoffs
- TTS comparison: ElevenLabs vs OpenAI vs Cartesia (Cartesia vendor source) — voice quality benchmarks (vendor bias, but directionally accurate)
- Speechmatics TTS API comparison 2026 — multi-provider benchmark overview
- RelaxFrens AI meditation product — competitor reference for personalization claims
- Auth.js v5 migration guide — App Router integration patterns
- Upstash Redis for Next.js session management — serverless session store patterns
- Future of Privacy Forum (California SB 243 analysis) — regulatory interpretation
- Psychology Today AI companions 2026 — product positioning context
- RisingStack LLM safety layers — safety architecture patterns
- Pipecat voice agent framework (GitHub) — reference implementation patterns
- ByteByteGo LLM memory problem — context drift patterns

### Tertiary (LOW confidence)
- Aggregator best-of wellness app lists — feature landscape (directional only, needs validation with real users)
- Community WebSocket audio streaming patterns — implementation reference only, verify against official docs

---
*Research completed: 2026-02-21*
*Ready for roadmap: yes*

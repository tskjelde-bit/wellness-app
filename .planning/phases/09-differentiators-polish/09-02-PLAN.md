---
phase: 09-differentiators-polish
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/hooks/use-audio-queue.ts
  - src/hooks/use-ambient-audio.ts
  - src/components/session/volume-mixer.tsx
autonomous: true
requirements: [DIFF-02, DIFF-03]

must_haves:
  truths:
    - "AudioPlaybackQueue routes audio through a GainNode instead of directly to destination"
    - "Ambient soundscape loops seamlessly in the background using AudioBufferSourceNode with loop=true"
    - "Voice and ambient volumes are independently adjustable via two range sliders"
    - "Volume changes are click-free using linearRampToValueAtTime"
  artifacts:
    - path: "src/hooks/use-audio-queue.ts"
      provides: "AudioPlaybackQueue with GainNode routing and exposed voiceGain"
      contains: "voiceGain"
    - path: "src/hooks/use-ambient-audio.ts"
      provides: "useAmbientAudio hook for looping background soundscapes"
      contains: "useAmbientAudio"
    - path: "src/components/session/volume-mixer.tsx"
      provides: "VolumeMixer component with voice/ambient sliders"
      contains: "VolumeMixer"
  key_links:
    - from: "src/hooks/use-audio-queue.ts"
      to: "AudioContext.destination"
      via: "voiceGain GainNode intermediary"
      pattern: "voiceGain\\.connect"
    - from: "src/hooks/use-ambient-audio.ts"
      to: "AudioContext.destination"
      via: "ambientGain GainNode intermediary"
      pattern: "ambientGain\\.connect"
    - from: "src/components/session/volume-mixer.tsx"
      to: "GainNode.gain"
      via: "linearRampToValueAtTime for smooth transitions"
      pattern: "linearRampToValueAtTime"
---

<objective>
Refactor the audio pipeline for dual-channel mixing and add ambient soundscape support.

Purpose: Enable independent volume control for voice and ambient audio (DIFF-03), and create the ambient audio loop infrastructure for background soundscapes (DIFF-02). The AudioPlaybackQueue must route through a GainNode instead of directly to AudioContext.destination, enabling the mixer to control voice volume separately from ambient volume.

Output: Refactored AudioPlaybackQueue with GainNode, useAmbientAudio hook, and VolumeMixer component.
</objective>

<execution_context>
@/Users/torbjorntest/.claude/get-shit-done/workflows/execute-plan.md
@/Users/torbjorntest/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-differentiators-polish/09-RESEARCH.md
@.planning/phases/04-tts-audio-streaming/04-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Refactor AudioPlaybackQueue for GainNode routing and create useAmbientAudio hook</name>
  <files>
    src/hooks/use-audio-queue.ts
    src/hooks/use-ambient-audio.ts
  </files>
  <action>
1. Refactor `AudioPlaybackQueue` in `src/hooks/use-audio-queue.ts`:
   - Add a `voiceGain: GainNode` property to the class.
   - Change constructor signature to `constructor(audioContext: AudioContext, voiceGain: GainNode)`.
   - Store `this.voiceGain = voiceGain`.
   - In `playNext()`, change `source.connect(this.audioContext.destination)` to `source.connect(this.voiceGain)`. This is the CRITICAL change that enables independent voice volume control.
   - All other methods (enqueue, pause, resume, stop, state getter) remain unchanged.

2. Update `useAudioQueue` hook in the same file:
   - In `initQueue()`:
     - After creating AudioContext, create a voiceGain GainNode: `const voiceGain = ctx.createGain(); voiceGain.gain.value = 1.0; voiceGain.connect(ctx.destination);`
     - Create an ambientGain GainNode: `const ambientGain = ctx.createGain(); ambientGain.gain.value = 0.3; ambientGain.connect(ctx.destination);`
     - Pass voiceGain to AudioPlaybackQueue constructor: `new AudioPlaybackQueue(ctx, voiceGain)`.
     - Store both GainNodes in refs: add `voiceGainRef` and `ambientGainRef` using useRef, and `audioContextRef` for the AudioContext.
   - Export from the hook: `audioContext: audioContextRef.current`, `voiceGain: voiceGainRef.current`, `ambientGain: ambientGainRef.current` (as state values via useState or direct ref reads -- use useState to trigger re-renders when they become available after initQueue).
   - To expose the GainNodes reactively: add `audioContext`, `voiceGain`, `ambientGain` to the returned object, stored via useState (set them in initQueue alongside the queue creation).

3. Create `src/hooks/use-ambient-audio.ts`:
   - `"use client"` directive.
   - Export `SOUNDSCAPE_OPTIONS` as a const array: `[{ id: "rain", label: "Rain" }, { id: "ocean", label: "Ocean" }, { id: "forest", label: "Forest" }, { id: "ambient", label: "Ambient" }, { id: "silence", label: "Silence" }]`.
   - Export `SOUNDSCAPE_URLS: Record<string, string>` mapping IDs to `/audio/ambient/{id}.mp3`, with "silence" mapping to empty string.
   - Export `useAmbientAudio(audioContext: AudioContext | null, ambientGain: GainNode | null)` hook:
     - `sourceRef` (useRef<AudioBufferSourceNode | null>) to track the current playing source.
     - `activeSoundscape` state (default "silence").
     - `startSoundscape(key: string)` callback:
       - If key is "silence" or no audioContext/ambientGain, stop existing source and set state, return.
       - Stop previous source if playing (`sourceRef.current?.stop()`).
       - Fetch the audio file URL, decode with `audioContext.decodeAudioData(arrayBuffer.slice(0))` (slice to prevent detached buffer issues per existing pattern).
       - Create AudioBufferSourceNode, set `loop = true`, connect to ambientGain, start.
       - Store in sourceRef.
     - `stopSoundscape()` callback: stop source, set null, set state to "silence".
     - Return `{ startSoundscape, stopSoundscape, activeSoundscape }`.
  </action>
  <verify>
    Run `npx tsc --noEmit` to verify no type errors. Verify AudioPlaybackQueue constructor takes GainNode. Verify useAudioQueue returns voiceGain and ambientGain. Verify useAmbientAudio exports hook and SOUNDSCAPE_OPTIONS.
  </verify>
  <done>
    AudioPlaybackQueue routes through voiceGain GainNode. useAudioQueue creates and exposes both voiceGain and ambientGain. useAmbientAudio hook can start/stop looping ambient soundscapes through the ambientGain channel. All audio shares ONE AudioContext (Research anti-pattern avoidance).
  </done>
</task>

<task type="auto">
  <name>Task 2: Create VolumeMixer component</name>
  <files>
    src/components/session/volume-mixer.tsx
  </files>
  <action>
1. Create `src/components/session/volume-mixer.tsx`:
   - `"use client"` directive.
   - Export a `setVolume` utility function: takes a GainNode and a number (0-1), uses `gainNode.gain.setValueAtTime(gainNode.gain.value, now)` then `gainNode.gain.linearRampToValueAtTime(value, now + 0.05)` for click-free 50ms ramp transitions (Research Pattern 3).
   - Export `VolumeMixer` component with props: `{ voiceGain: GainNode | null; ambientGain: GainNode | null }`.
   - Render two range sliders in a compact vertical layout using existing theme colors:
     - "Voice" slider: min=0, max=100, defaultValue=100, onChange calls `setVolume(voiceGain, value / 100)`.
     - "Ambient" slider: min=0, max=100, defaultValue=30 (ambient starts lower), onChange calls `setVolume(ambientGain, value / 100)`.
   - Styling: `flex flex-col gap-2 w-full max-w-[200px]`. Labels use `text-xs text-cream/50`. Sliders use `accent-rose` for voice and `accent-blush` for ambient. Keep it compact -- this goes in the session screen's bottom controls area.
   - Guard: if voiceGain and ambientGain are both null, return null (not yet initialized).
  </action>
  <verify>
    Run `npx tsc --noEmit` to verify no type errors. Verify VolumeMixer exports and renders two range inputs.
  </verify>
  <done>
    VolumeMixer component renders two labeled range sliders. Volume changes use 50ms linear ramp for click-free transitions. Component uses existing theme tokens (cream, rose, blush). Ready for integration into SessionScreen in Plan 03.
  </done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes with no errors
- AudioPlaybackQueue.playNext() connects source to this.voiceGain (not this.audioContext.destination)
- useAudioQueue returns audioContext, voiceGain, and ambientGain
- useAmbientAudio creates AudioBufferSourceNode with loop=true
- VolumeMixer uses linearRampToValueAtTime for smooth transitions
- Both GainNodes connect to the same AudioContext.destination
</verification>

<success_criteria>
Audio pipeline supports dual-channel mixing. Voice audio routes through voiceGain, ambient loops route through ambientGain, both feeding into the same AudioContext.destination. VolumeMixer provides independent control of both channels with click-free transitions.
</success_criteria>

<output>
After completion, create `.planning/phases/09-differentiators-polish/09-02-SUMMARY.md`
</output>

---
phase: 05-session-state-machine-orchestration
plan: 02
type: execute
wave: 2
depends_on:
  - 05-01
files_modified:
  - src/lib/session/orchestrator.ts
  - src/lib/llm/generate-session.ts
  - src/lib/session-store.ts
autonomous: true
requirements:
  - SESS-04
  - SESS-06

must_haves:
  truths:
    - "Orchestrator drives multiple sequential LLM calls, one per phase, with phase-specific instructions"
    - "LLM calls are chained via previous_response_id so the model retains context across phases"
    - "Phase transitions occur when sentence budget is reached, not mid-sentence"
    - "Wind-down transition hints are injected in the last few sentences of each phase for natural transitions"
    - "Session phase state persists in Redis and survives reconnection"
    - "Session completes after resolution phase finishes"
  artifacts:
    - path: "src/lib/session/orchestrator.ts"
      provides: "SessionOrchestrator class with async generator run() method yielding OrchestratorEvents"
      exports: ["SessionOrchestrator", "OrchestratorEvent"]
    - path: "src/lib/llm/generate-session.ts"
      provides: "Extended streamLlmTokens with previousResponseId, store, and onResponseId support"
      exports: ["streamLlmTokens", "chunkBySentence", "filterSafety", "generateSession"]
    - path: "src/lib/session-store.ts"
      provides: "Extended SessionState with phase orchestration fields"
      exports: ["SessionState", "getSessionState", "setSessionState"]
  key_links:
    - from: "src/lib/session/orchestrator.ts"
      to: "src/lib/session/phase-machine.ts"
      via: "imports getNextPhase, isTerminalPhase, SessionPhase for FSM progression"
      pattern: "import.*getNextPhase.*isTerminalPhase.*from.*phase-machine"
    - from: "src/lib/session/orchestrator.ts"
      to: "src/lib/session/phase-prompts.ts"
      via: "imports buildPhaseInstructions and TRANSITION_HINTS for per-phase LLM calls"
      pattern: "import.*buildPhaseInstructions.*TRANSITION_HINTS.*from.*phase-prompts"
    - from: "src/lib/session/orchestrator.ts"
      to: "src/lib/llm/generate-session.ts"
      via: "calls streamLlmTokens with previousResponseId for context chaining"
      pattern: "streamLlmTokens.*previousResponseId"
    - from: "src/lib/session/orchestrator.ts"
      to: "src/lib/session-store.ts"
      via: "calls setSessionState to persist phase progression in Redis"
      pattern: "setSessionState.*currentPhase"
    - from: "src/lib/llm/generate-session.ts"
      to: "openai.responses.create"
      via: "passes store: true and previous_response_id for context chaining"
      pattern: "store:\\s*true.*previous_response_id"
---

<objective>
Build the SessionOrchestrator that drives multi-phase LLM generation with context chaining, extend the LLM pipeline to support `previous_response_id`, and extend Redis session state for phase tracking.

Purpose: This is the core engine that transforms the single-prompt streaming pipeline into a structured 5-phase session. The orchestrator makes one LLM call per phase with distinct instructions while OpenAI retains conversational context via `previous_response_id`. Phase state persists in Redis for crash recovery.

Output: SessionOrchestrator class, extended streamLlmTokens, and extended SessionState.
</objective>

<execution_context>
@/Users/torbjorntest/.claude/get-shit-done/workflows/execute-plan.md
@/Users/torbjorntest/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-session-state-machine-orchestration/05-RESEARCH.md
@.planning/phases/05-session-state-machine-orchestration/05-01-SUMMARY.md

@src/lib/llm/generate-session.ts (current pipeline to extend)
@src/lib/session-store.ts (current SessionState to extend)
@src/lib/tts/audio-pipeline.ts (streamSessionAudio -- NOT modified, but orchestrator replaces its role)
@src/lib/safety/constants.ts (SAFETY_SYSTEM_PROMPT used by phase prompts)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend streamLlmTokens for phase chaining and extend SessionState for phase tracking</name>
  <files>
    src/lib/llm/generate-session.ts
    src/lib/session-store.ts
  </files>
  <action>
**File 1: Extend `src/lib/llm/generate-session.ts`**

Modify `streamLlmTokens` to support multi-phase context chaining via OpenAI `previous_response_id`. The existing function signature and behavior must remain backward-compatible (all new parameters are optional).

Changes to `streamLlmTokens`:
1. Add optional parameters to the options object:
   - `previousResponseId?: string` -- chains to a prior response for context continuity
   - `store?: boolean` -- enables server-side response retention (required for chaining, defaults to false for backward compat)
   - `onResponseId?: (id: string) => void` -- callback to capture the response ID from the `response.created` event
   - `signal?: AbortSignal` -- for cancellation propagation from the orchestrator
   - `userMessage?: string` -- override the default "Begin the session." input message (subsequent phases use "Continue. The session is now entering the [phase] phase.")
   - `instructions?: string` -- override for complete instructions string (when provided, skip calling buildSessionInstructions and use this directly; this is how the orchestrator passes pre-built phase instructions)
2. In the `openai.responses.create` call:
   - Add `store: options.store ?? false`
   - Add `...(options.previousResponseId && { previous_response_id: options.previousResponseId })`
   - Use `options.instructions ?? buildSessionInstructions(sessionPrompt)` for the `instructions` parameter
   - Use `options.userMessage ?? "Begin the session."` for the input message content
3. In the streaming loop, capture the response ID:
   - Add handler for `event.type === "response.created"`: call `options?.onResponseId?.(event.response.id)`
4. Respect `signal` for cancellation:
   - Check `options?.signal?.aborted` before iterating stream events. If aborted, return early.

Do NOT modify `chunkBySentence`, `filterSafety`, or `generateSession` -- they remain unchanged. The orchestrator will call `streamLlmTokens` directly (not `generateSession`) because it manages the chunking and safety filtering per-phase itself.

**CRITICAL (Research Pitfall 6):** `store: true` MUST be passed when chaining responses. Without it, `previous_response_id` will fail with "Response not found" on the second phase.

**File 2: Extend `src/lib/session-store.ts`**

Add phase orchestration fields to `SessionState` interface:

1. Import `SessionPhase` from `@/lib/session/phase-machine`
2. Add new fields to `SessionState` (all optional to maintain backward compatibility with existing sessions):
   - `currentPhase?: SessionPhase` -- current phase in the FSM
   - `phaseStartedAt?: number` -- timestamp when current phase began
   - `sentencesInPhase?: number` -- sentence counter within current phase
   - `totalSentences?: number` -- cumulative sentence count across all phases
   - `previousResponseId?: string | null` -- OpenAI response ID for context chaining
   - `phaseBudgets?: Record<SessionPhase, number>` -- sentence budgets per phase
   - `sessionLengthMinutes?: number` -- 10, 15, 20, or 30
  </action>
  <verify>Run `npx tsc --noEmit` -- no type errors. Verify that `streamLlmTokens("test")` still works without new options (backward compatible). Verify SessionState now has `currentPhase` field in its type definition.</verify>
  <done>streamLlmTokens accepts previousResponseId, store, onResponseId, signal, userMessage, and instructions parameters. SessionState includes phase orchestration fields. Both are backward-compatible with existing code.</done>
</task>

<task type="auto">
  <name>Task 2: Create SessionOrchestrator class with multi-phase async generator</name>
  <files>src/lib/session/orchestrator.ts</files>
  <action>
Create `src/lib/session/orchestrator.ts` with the `SessionOrchestrator` class. This is the core engine that drives the 5-phase session flow.

1. Define `OrchestratorEvent` discriminated union type:
   - `{ type: "phase_start"; phase: SessionPhase; phaseIndex: number }`
   - `{ type: "sentence"; text: string; phase: SessionPhase; index: number }` (index is global sentence count)
   - `{ type: "phase_transition"; from: SessionPhase; to: SessionPhase }`
   - `{ type: "session_complete" }`
   - `{ type: "error"; message: string }`

2. Define `OrchestratorOptions` interface:
   - `sessionId: string`
   - `sessionLengthMinutes: number` (default 15)

3. Create `SessionOrchestrator` class:
   - Constructor takes `OrchestratorOptions`
   - Private state: `phase: SessionPhase` (starts at "atmosphere"), `previousResponseId: string | null`, `sentencesInPhase: number`, `totalSentences: number`, `phaseBudgets: Record<SessionPhase, PhaseConfig>` (from `getSessionBudgets`)

4. Implement `async *run(signal: AbortSignal): AsyncGenerator<OrchestratorEvent>`:
   - **Outer loop:** While not at terminal phase (or terminal with 0 sentences), iterate phases
   - **Per-phase:**
     a. Yield `phase_start` event
     b. Determine if wind-down hint needed: call `shouldTransition(sentencesInPhase, phaseBudgets[phase])` helper
     c. Build instructions via `buildPhaseInstructions(phase, transitionHint)` where transitionHint is TRANSITION_HINTS[phase] when in wind-down zone, undefined otherwise
     d. Determine user message: first phase uses "Begin the session.", subsequent phases use `"Continue. The session is now entering the ${phase} phase."`
     e. Call `streamLlmTokens("", { instructions, previousResponseId, store: true, userMessage, onResponseId, signal })` -- pass empty string as sessionPrompt since instructions are pre-built
     f. Pipe token stream through `chunkBySentence` then `filterSafety` (import from `@/lib/llm/generate-session`)
     g. For each yielded sentence: increment `sentencesInPhase` and `totalSentences`, yield `sentence` event
     h. After each sentence, check transition: if `sentencesInPhase >= budget.sentenceBudget`, break inner loop
     i. **IMPORTANT for wind-down:** When `sentencesInPhase >= budget.windDownAt` AND we haven't yet injected the transition hint for the current LLM call, we must let the current call finish and start a NEW call with the transition hint included in instructions. Implementation: track a `hintInjected` flag per phase. When entering wind-down zone, break the inner sentence loop, then re-enter with updated instructions including the transition hint. This ensures the last few sentences of each phase naturally transition.
     j. Actually, simpler approach per research: inject the transition hint into instructions UPFRONT when starting a phase if the budget is small enough that the whole phase could be in wind-down. For larger phases, make TWO LLM calls per phase: first call without hint (sentences 0 to windDownAt), second call with hint (sentences windDownAt to sentenceBudget). Both calls use `previous_response_id` for continuity.
     k. **Simplest viable approach (implement this):** Make a SINGLE LLM call per phase. If `sentencesInPhase >= windDownAt`, include the transition hint in a SECOND short LLM call for just the remaining sentences. So the flow per phase is: Call 1 (main content, no hint) -> when windDownAt reached, break -> Call 2 (with transition hint, short budget) -> when sentenceBudget reached or stream ends, advance phase.
   - **Phase transition:** After inner loop completes, capture response ID, call `getNextPhase(phase)`. If next exists: yield `phase_transition` event, update phase, reset sentencesInPhase to 0, persist state to Redis via `setSessionState`
   - **Terminal phase complete:** When isTerminalPhase and sentencesInPhase > 0, yield `session_complete` and return
   - **Abort handling:** Check `signal.aborted` at the top of each loop iteration. Return cleanly on abort.

5. Implement private `persistState(sessionId: string)` method that calls `setSessionState` with current orchestrator state (currentPhase, phaseStartedAt, sentencesInPhase, totalSentences, previousResponseId, phaseBudgets sentence values, sessionLengthMinutes). Preserves existing SessionState fields (userId, consent flags) by reading current state first and merging.

6. Implement private `shouldTransition(sentencesInPhase: number, config: PhaseConfig): "continue" | "wind_down" | "transition"`:
   - If sentencesInPhase >= config.sentenceBudget: return "transition"
   - If sentencesInPhase >= config.windDownAt: return "wind_down"
   - Return "continue"

7. Export `SessionOrchestrator`, `OrchestratorEvent`, and `OrchestratorOptions` from the module.

8. Update `src/lib/session/index.ts` barrel to also export from `./orchestrator`.

**Key design decisions:**
- Orchestrator yields TEXT events (not audio). The WebSocket handler (Plan 03) feeds text into the TTS pipeline.
- Each phase gets 1-2 LLM calls (main + optional wind-down) chained via `previous_response_id`.
- `store: true` on every LLM call (Research Pitfall 6).
- Sentence counting is primary transition signal; no wall-clock timer in v1 (Research recommendation).
- Pause behavior: The orchestrator does NOT handle pauses. The WebSocket handler pauses by not pulling from the orchestrator's generator (existing pause gate pattern from Phase 4).
  </action>
  <verify>Run `npx tsc --noEmit` -- no type errors. Verify SessionOrchestrator can be instantiated with `{ sessionId: "test", sessionLengthMinutes: 15 }`. Verify OrchestratorEvent type includes all 5 event types. Verify orchestrator imports and uses buildPhaseInstructions, streamLlmTokens, chunkBySentence, filterSafety.</verify>
  <done>SessionOrchestrator drives 5-phase session flow with per-phase LLM calls, previous_response_id chaining, sentence-budget transitions with wind-down hints, and Redis state persistence. Exported via @/lib/session barrel.</done>
</task>

</tasks>

<verification>
1. `npx tsc --noEmit` passes with zero errors
2. `streamLlmTokens` still works when called without new options (backward compatible)
3. `streamLlmTokens` accepts `previousResponseId`, `store`, `onResponseId`, `signal`, `userMessage`, `instructions` in options
4. `SessionState` interface includes `currentPhase`, `previousResponseId`, `sentencesInPhase`, `phaseBudgets`, `sessionLengthMinutes`
5. `SessionOrchestrator` constructor accepts sessionId and sessionLengthMinutes
6. `orchestrator.run(signal)` returns an AsyncGenerator of OrchestratorEvent
7. OrchestratorEvent discriminated union has types: phase_start, sentence, phase_transition, session_complete, error
8. Orchestrator imports and calls `buildPhaseInstructions`, `streamLlmTokens`, `chunkBySentence`, `filterSafety`
9. Orchestrator passes `store: true` in all streamLlmTokens calls
10. Orchestrator calls `setSessionState` on phase transitions
</verification>

<success_criteria>
- streamLlmTokens supports previous_response_id chaining with store: true
- SessionOrchestrator drives sequential phase progression through all 5 phases
- Phase transitions triggered by sentence budget (not mid-sentence cuts)
- Wind-down hints injected in final sentences of each phase for natural transitions
- Session state persisted in Redis on each phase transition
- All existing pipeline code remains backward-compatible
</success_criteria>

<output>
After completion, create `.planning/phases/05-session-state-machine-orchestration/05-02-SUMMARY.md`
</output>

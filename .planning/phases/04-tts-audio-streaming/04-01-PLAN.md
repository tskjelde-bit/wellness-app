---
phase: 04-tts-audio-streaming
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/lib/env.ts
  - src/lib/tts/elevenlabs-client.ts
  - src/lib/tts/tts-service.ts
  - src/lib/tts/audio-pipeline.ts
  - src/lib/tts/index.ts
  - package.json
autonomous: true
requirements:
  - VOIC-03
  - VOIC-04
user_setup:
  - service: elevenlabs
    why: "Text-to-speech audio synthesis"
    env_vars:
      - name: ELEVENLABS_API_KEY
        source: "ElevenLabs Dashboard -> Profile + API Key (https://elevenlabs.io/app/settings/api-keys)"

must_haves:
  truths:
    - "ElevenLabs SDK is installed and configured with module-level singleton"
    - "TTS service converts a text sentence into an async stream of audio chunks (Uint8Array)"
    - "Audio pipeline connects generateSession async generator to TTS, yielding audio chunks per sentence"
    - "Previous text context is passed to ElevenLabs for prosody continuity across sentences"
    - "AbortController signal propagates through the pipeline for clean cancellation"
  artifacts:
    - path: "src/lib/tts/elevenlabs-client.ts"
      provides: "ElevenLabs SDK singleton and TTS configuration constants"
      contains: "ElevenLabsClient"
    - path: "src/lib/tts/tts-service.ts"
      provides: "synthesizeSentence async generator"
      exports: ["synthesizeSentence"]
    - path: "src/lib/tts/audio-pipeline.ts"
      provides: "streamSessionAudio pipeline function"
      exports: ["streamSessionAudio"]
    - path: "src/lib/tts/index.ts"
      provides: "Barrel exports for TTS module"
    - path: "src/lib/env.ts"
      provides: "ELEVENLABS_API_KEY validation"
      contains: "ELEVENLABS_API_KEY"
  key_links:
    - from: "src/lib/tts/audio-pipeline.ts"
      to: "@/lib/llm"
      via: "import generateSession"
      pattern: "import.*generateSession.*from.*@/lib/llm"
    - from: "src/lib/tts/audio-pipeline.ts"
      to: "src/lib/tts/tts-service.ts"
      via: "import synthesizeSentence"
      pattern: "import.*synthesizeSentence"
    - from: "src/lib/tts/tts-service.ts"
      to: "src/lib/tts/elevenlabs-client.ts"
      via: "import elevenlabs client"
      pattern: "import.*elevenlabs.*from.*elevenlabs-client"
---

<objective>
Create the server-side TTS service and cascading audio pipeline that converts Phase 3's sentence stream into audio chunks via ElevenLabs.

Purpose: This is the core server-side audio generation layer. It takes safe, complete sentences from `generateSession` and produces streaming audio chunks ready for WebSocket delivery to clients. The cascading pipeline design (LLM generates sentence N+1 while TTS synthesizes sentence N) targets <2 seconds to first audio.

Output: ElevenLabs SDK integration, TTS service module, audio pipeline module, env validation update.
</objective>

<execution_context>
@/Users/torbjorntest/.claude/get-shit-done/workflows/execute-plan.md
@/Users/torbjorntest/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-tts-audio-streaming/04-RESEARCH.md
@.planning/phases/03-llm-text-generation-pipeline/03-02-SUMMARY.md
@src/lib/llm/generate-session.ts
@src/lib/llm/index.ts
@src/lib/env.ts
@package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install ElevenLabs SDK and create TTS service</name>
  <files>
    package.json
    src/lib/env.ts
    src/lib/tts/elevenlabs-client.ts
    src/lib/tts/tts-service.ts
    src/lib/tts/index.ts
  </files>
  <action>
    1. Install dependencies:
       ```bash
       npm install @elevenlabs/elevenlabs-js
       ```

    2. Add ELEVENLABS_API_KEY to env validation in `src/lib/env.ts`:
       - Add `ELEVENLABS_API_KEY: z.string().min(1)` to the envSchema object

    3. Create `src/lib/tts/elevenlabs-client.ts`:
       - Module-level ElevenLabsClient singleton (matches OpenAI singleton pattern in generate-session.ts)
       - The SDK reads ELEVENLABS_API_KEY from process.env automatically
       - Export `TTS_CONFIG` object with:
         - `voiceId`: string constant (use "JBFqnCBsd6RMkjVDRZzb" -- ElevenLabs "George" voice, warm male narration; placeholder until user selects final voice)
         - `modelId`: "eleven_flash_v2_5" (75ms TTFB, lowest latency for streaming)
         - `outputFormat`: "mp3_44100_128" as const
         - `optimizeStreamingLatency`: 3 (max optimization without disabling text normalizer)
         - `voiceSettings`: { stability: 0.7, similarityBoost: 0.75, style: 0.3, speed: 0.95 }

    4. Create `src/lib/tts/tts-service.ts`:
       - Export async generator `synthesizeSentence(text, options?)`:
         - `options`: `{ voiceId?: string; previousText?: string; nextText?: string; signal?: AbortSignal }`
         - Calls `elevenlabs.textToSpeech.stream(voiceId, { text, modelId, outputFormat, optimizeStreamingLatency, previousText, nextText, voiceSettings })` from the SDK
         - The SDK returns a ReadableStream. Iterate the stream with `for await (const chunk of audioStream)` and yield each `Uint8Array` chunk
         - Pass `signal` option to the SDK call via `abortSignal` parameter for clean cancellation
         - On error: log the error and return (do not throw -- downstream handles missing audio gracefully, similar to LLM error pattern)

    5. Create `src/lib/tts/index.ts`:
       - Barrel exports: `synthesizeSentence` from tts-service, `elevenlabs` and `TTS_CONFIG` from elevenlabs-client
  </action>
  <verify>
    - `npm ls @elevenlabs/elevenlabs-js` shows the package is installed
    - `npx tsc --noEmit` passes with no type errors
    - `src/lib/tts/index.ts` exports synthesizeSentence, elevenlabs, TTS_CONFIG
    - `src/lib/env.ts` includes ELEVENLABS_API_KEY in schema
  </verify>
  <done>
    ElevenLabs SDK installed, env validation includes ELEVENLABS_API_KEY, TTS service exports an async generator that converts text to audio chunks via ElevenLabs streaming API with abort support and prosody context.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create cascading audio pipeline</name>
  <files>
    src/lib/tts/audio-pipeline.ts
    src/lib/tts/index.ts
  </files>
  <action>
    1. Create `src/lib/tts/audio-pipeline.ts`:
       - Import `generateSession` from `@/lib/llm`
       - Import `synthesizeSentence` from `./tts-service`

       - Define `AudioChunkEvent` type:
         ```typescript
         type AudioChunkEvent =
           | { type: "sentence_start"; text: string; index: number }
           | { type: "audio"; data: Uint8Array }
           | { type: "sentence_end"; index: number }
           | { type: "session_end" };
         ```

       - Export async generator `streamSessionAudio(sessionPrompt, options?)`:
         - `options`: `{ model?: string; temperature?: number; signal?: AbortSignal }`
         - Create AbortController if no signal provided; wire abort propagation
         - Track `previousText` accumulator (last 1000 chars for ElevenLabs prosody context)
         - Track `sentenceIndex` counter starting at 0
         - Iterate `generateSession(sessionPrompt, { model, temperature })`:
           - Check `signal.aborted` at start of each iteration; if true, return early
           - Yield `{ type: "sentence_start", text: sentence, index: sentenceIndex }`
           - Call `synthesizeSentence(sentence, { previousText: previousText.slice(-1000), signal })`
           - For each audio chunk yielded: yield `{ type: "audio", data: chunk }`
           - Yield `{ type: "sentence_end", index: sentenceIndex }`
           - Append sentence to previousText
           - Increment sentenceIndex
         - After loop, yield `{ type: "session_end" }`
         - Wrap entire pipeline in try/catch: on AbortError, yield session_end and return; on other errors, log and yield session_end

    2. Update `src/lib/tts/index.ts`:
       - Add exports: `streamSessionAudio` and `type AudioChunkEvent` from audio-pipeline
  </action>
  <verify>
    - `npx tsc --noEmit` passes with no type errors
    - `src/lib/tts/index.ts` exports streamSessionAudio, AudioChunkEvent, synthesizeSentence, elevenlabs, TTS_CONFIG
    - `grep -r "generateSession" src/lib/tts/audio-pipeline.ts` confirms import from @/lib/llm
    - `grep -r "synthesizeSentence" src/lib/tts/audio-pipeline.ts` confirms usage of TTS service
  </verify>
  <done>
    Cascading audio pipeline connects generateSession (Phase 3) to TTS, yielding typed AudioChunkEvents with sentence metadata. AbortController propagation enables clean cancellation. Previous text context maintains prosody continuity across sentences.
  </done>
</task>

</tasks>

<verification>
- `npm ls @elevenlabs/elevenlabs-js` confirms SDK installed
- `npx tsc --noEmit` passes -- all types resolve correctly
- TTS module exports: synthesizeSentence, streamSessionAudio, AudioChunkEvent, elevenlabs, TTS_CONFIG
- audio-pipeline.ts imports generateSession from @/lib/llm (Phase 3 integration confirmed)
- env.ts validates ELEVENLABS_API_KEY
</verification>

<success_criteria>
1. ElevenLabs SDK is installed and importable
2. ELEVENLABS_API_KEY is validated in env schema
3. synthesizeSentence converts text to async audio chunk stream with prosody context
4. streamSessionAudio produces typed AudioChunkEvents from the full LLM->TTS pipeline
5. AbortController signal propagates through both TTS calls and pipeline iteration
6. TypeScript compiles with no errors
</success_criteria>

<output>
After completion, create `.planning/phases/04-tts-audio-streaming/04-01-SUMMARY.md`
</output>
